import logging
from pathlib import Path
import time

from ..core.data_types import ColorData, RGB


def extract_colors_kmeans(
    image_path: str | Path,
    num_colors: int = 8,
    resize_dim: tuple | None = None,
    pixel_sample_count: int | None = None,
    kmeans_iteration: int = 10,
) -> list[ColorData]:
    """
    Extract dominant colors using K-means clustering algorithm.

    Args:
        num_colors: Number of colors to extract.

    Returns:
        list[ColorData]: A list of ColorData objects, each containing an RGB color
                         and its coverage percentage.
    """
    # NOTE: generated by AI, needs review

    start = time.perf_counter()
    import numpy as np  # pylint: disable= import-outside-toplevel
    from PIL import Image  # pylint: disable= import-outside-toplevel

    # using import inside function to avoid slow startup time,
    # when no color extraction is needed
    # for example --validate, no extraction is needed

    end = time.perf_counter()
    logging.debug("Numpy and Pillow took %s to import", end - start)

    try:
        # Set seed at the very beginning for consistency
        np.random.seed(69)

        with Image.open(image_path) as img:
            # Convert to RGB

            logging.debug("Pixel format: %s", img.mode)
            img.draft("RGB", resize_dim)

            if img.mode not in ("RGB", "RGBA"):
                start = time.perf_counter()
                img = img.convert("RGB")
                end = time.perf_counter()

                logging.debug("Image Convert to Rgb Colorspace time: %s", end - start)
            start = time.perf_counter()
            if resize_dim:
                if not (img.width <= resize_dim[0] and img.height <= resize_dim[1]):
                    # img.thumbnail(resize_dim, Image.Resampling.NEAREST)
                    img.thumbnail(resize_dim, Image.Resampling.LANCZOS)

            end = time.perf_counter()
            logging.warning("Resize time: %s", end - start)

            # NOTE: instead of resizing the image we could convert the whole
            # image into an array and then use stride sampling to
            # reduce the number of pixels this might be faster
            # than resize, but will definitely use up more memory

            start = time.perf_counter()
            # Convert to numpy array
            img_array = np.array(img, dtype=np.float32)

            # ignore alpha channel if present
            if img_array.shape[-1] > 3:
                img_array = img_array[..., :3]

            # Reshape to 2D array (pixels x RGB)
            pixels = img_array.reshape(-1, 3)

            num_colors = min(num_colors, len(pixels))

            if num_colors < 1:
                raise ValueError("Image must contain at least one color")

            # Sample pixels for speed based on quality setting
            if pixel_sample_count:
                if len(pixels) > pixel_sample_count:
                    indices = np.random.choice(
                        len(pixels), pixel_sample_count, replace=False
                    )
                    sampled_pixels = pixels[indices]
                else:
                    sampled_pixels = pixels
            else:
                sampled_pixels = pixels

            # K-means++ initialization for better starting centroids
            centroids = np.zeros((num_colors, 3), dtype=np.float32)
            centroids[0] = sampled_pixels[np.random.choice(len(sampled_pixels))]

            for i in range(1, num_colors):
                # Use squared distances (no sqrt needed)
                distances_sq = np.min(
                    ((sampled_pixels[:, np.newaxis, :] - centroids[:i]) ** 2).sum(
                        axis=2
                    ),
                    axis=1,
                )

                # Avoid division by zero
                total_distance = distances_sq.sum()
                if total_distance > 0:
                    probabilities = distances_sq / total_distance
                else:
                    probabilities = np.ones(len(sampled_pixels)) / len(sampled_pixels)

                centroids[i] = sampled_pixels[
                    np.random.choice(len(sampled_pixels), p=probabilities)
                ]

            # K-means iterations based on quality setting
            for _ in range(kmeans_iteration):
                # Use squared distances (faster, same result for argmin)
                distances_sq = (
                    (sampled_pixels[:, np.newaxis, :] - centroids) ** 2
                ).sum(axis=2)
                assignments = np.argmin(distances_sq, axis=1)

                # Update centroids
                new_centroids = np.zeros_like(centroids)
                cluster_has_points = np.zeros(num_colors, dtype=bool)

                for i in range(num_colors):
                    mask = assignments == i
                    if mask.any():
                        new_centroids[i] = sampled_pixels[mask].mean(axis=0)
                        cluster_has_points[i] = True
                    else:
                        # Reinitialize empty cluster to the farthest point
                        farthest_idx = np.argmax(distances_sq.min(axis=1))
                        new_centroids[i] = sampled_pixels[farthest_idx]
                        cluster_has_points[i] = True

                # Check convergence
                if np.allclose(centroids, new_centroids, atol=1e-4):
                    centroids = new_centroids
                    break

                centroids = new_centroids

            # Final assignment to get accurate coverage
            distances_sq = ((sampled_pixels[:, np.newaxis, :] - centroids) ** 2).sum(
                axis=2
            )
            assignments = np.argmin(distances_sq, axis=1)

            # Calculate coverage for each color
            counts = np.bincount(assignments, minlength=num_colors)
            coverages = counts / len(sampled_pixels)

            # Sort colors by dominance
            sorted_indices = np.argsort(counts)[::-1]

            # Build result list of ColorData
            result_list = []
            for idx in sorted_indices:
                if counts[idx] > 0:  # Only include colors that appear
                    r, g, b = (int(c) for c in np.clip(centroids[idx], 0, 255))
                    coverage = float(coverages[idx])
                    result_list.append(ColorData(RGB(r, g, b), coverage))

            end = time.perf_counter()
            logging.warning("Kmeans time: %s", end - start)
            return result_list
    except Exception as e:
        raise RuntimeError("Error while extracting colors") from e


def extract_colors(
    image_path: str,
    num_colors: int = 8,
    preset: str = "balanced",
    sort_by: str = "luma",
) -> list[ColorData]:
    """
    Extract dominant colors from an image.
    Args:
        sort_by: Sort colors by 'luma' or 'coverage' (default: 'luma')
    Returns:
        List of ColorData[RGB,coverage,luma]
    """
    SUPPORTED_PRESET = ["high", "balanced", "fast"]  # pylint: disable=invalid-name
    SUPPORTED_SORT = ["luma", "coverage"]  # pylint: disable=invalid-name

    if preset not in SUPPORTED_PRESET:
        raise ValueError(
            f"{preset} is not a valid Preset. Select something from {', '.join(SUPPORTED_PRESET)}"
        )

    if sort_by not in SUPPORTED_SORT:
        raise ValueError(
            f"{sort_by} is not a valid sort option. Select something from {', '.join(SUPPORTED_SORT)}"
        )

    resize_dim: tuple[int, int]
    pixel_sample_count: int
    kmeans_iteration: int
    if preset == "fast":
        resize_dim = (100, 100)
        pixel_sample_count = 1000
        kmeans_iteration = 5
    elif preset == "high":
        resize_dim = (500, 500)
        pixel_sample_count = 10000
        kmeans_iteration = 20
    else:  # balanced
        resize_dim = (150, 150)
        pixel_sample_count = 4000
        kmeans_iteration = 10

    color_data_list: list[ColorData] = extract_colors_kmeans(
        image_path=image_path,
        num_colors=num_colors,
        resize_dim=resize_dim,
        pixel_sample_count=pixel_sample_count,
        kmeans_iteration=kmeans_iteration,
    )

    # Sort by the specified key
    if sort_by == "luma":
        color_data_list.sort(key=lambda x: x.rgb.luma, reverse=True)

    else:
        color_data_list.sort(key=lambda x: x.coverage, reverse=True)

    return color_data_list
