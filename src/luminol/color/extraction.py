from pathlib import Path
import time
import logging
from .color_computation import luma
from ..utils.data_types import RGB, ColorData


def extract_colors_kmeans(
    image_path: str | Path,
    num_colors: int = 8,
    resize_dim: tuple = (300, 300),
    pixel_sample_count: int = 4000,
    kmeans_iteration: int = 10,
) -> dict[tuple[int, int, int], float]:
    """
    Extract dominant colors using K-means clustering algorithm.

    Args:
        num_colors: Number of colors to extract.

    Returns:
        dict[tuple[int, int, int], float]: dictionary mapping RGB color tuples to coverage percentages.
                                            Format: (255, 128, 0) -> 0.45
    """
    # NOTE: generated by AI, needs review

    start = time.perf_counter()
    import numpy as np
    from PIL import Image

    # using import inside function to avoid slow startup time, when no color extraction is needed
    # for example --validate, no extraction is needed

    end = time.perf_counter()
    print(f"Numpy and Pillow took {end - start} to import")

    try:
        # Set seed at the very beginning for consistency
        np.random.seed(69)

        with Image.open(image_path) as img:
            # Convert to RGB

            print(img.mode)
            img.draft("RGB", resize_dim)

            if img.mode not in ("RGB", "RGBA"):
                start = time.perf_counter()
                img = img.convert("RGB")
                end = time.perf_counter()
                logging.info(f"Image Convert to Rgb Colorspace time: {end - start}")

            start = time.perf_counter()
            if not (img.width <= resize_dim[0] and img.height <= resize_dim[1]):
                # img.thumbnail(resize_dim, Image.Resampling.NEAREST)
                img.thumbnail(resize_dim, Image.Resampling.LANCZOS)

            end = time.perf_counter()
            logging.warning(f"Resize time: {end - start}")

            # NOTE: instead of resizing the image we could convert the whole image into an array and then
            #       use stride sampling to reduce the number of pixels
            #       this might be faster than resize, but will definitely use up more memory

            start = time.perf_counter()
            # Convert to numpy array
            img_array = np.array(img, dtype=np.float32)

            # ignore alpha channel if present
            if img_array.shape[-1] > 3:
                img_array = img_array[..., :3]

            # Reshape to 2D array (pixels x RGB)
            pixels = img_array.reshape(-1, 3)

            num_colors = min(num_colors, len(pixels))

            if num_colors < 1:
                raise ValueError("Image must contain at least one color")

            # Sample pixels for speed based on quality setting
            if len(pixels) > pixel_sample_count:
                indices = np.random.choice(
                    len(pixels), pixel_sample_count, replace=False
                )
                sampled_pixels = pixels[indices]
            else:
                sampled_pixels = pixels

            # K-means++ initialization for better starting centroids
            centroids = np.zeros((num_colors, 3), dtype=np.float32)
            centroids[0] = sampled_pixels[np.random.choice(len(sampled_pixels))]

            for i in range(1, num_colors):
                # Use squared distances (no sqrt needed)
                distances_sq = np.min(
                    ((sampled_pixels[:, np.newaxis, :] - centroids[:i]) ** 2).sum(
                        axis=2
                    ),
                    axis=1,
                )

                # Avoid division by zero
                total_distance = distances_sq.sum()
                if total_distance > 0:
                    probabilities = distances_sq / total_distance
                else:
                    probabilities = np.ones(len(sampled_pixels)) / len(sampled_pixels)

                centroids[i] = sampled_pixels[
                    np.random.choice(len(sampled_pixels), p=probabilities)
                ]

            # K-means iterations based on quality setting
            for _ in range(kmeans_iteration):
                # Use squared distances (faster, same result for argmin)
                distances_sq = (
                    (sampled_pixels[:, np.newaxis, :] - centroids) ** 2
                ).sum(axis=2)
                assignments = np.argmin(distances_sq, axis=1)

                # Update centroids
                new_centroids = np.zeros_like(centroids)
                cluster_has_points = np.zeros(num_colors, dtype=bool)

                for i in range(num_colors):
                    mask = assignments == i
                    if mask.any():
                        new_centroids[i] = sampled_pixels[mask].mean(axis=0)
                        cluster_has_points[i] = True
                    else:
                        # Reinitialize empty cluster to the farthest point
                        farthest_idx = np.argmax(distances_sq.min(axis=1))
                        new_centroids[i] = sampled_pixels[farthest_idx]
                        cluster_has_points[i] = True

                # Check convergence
                if np.allclose(centroids, new_centroids, atol=1e-4):
                    centroids = new_centroids
                    break

                centroids = new_centroids

            # Final assignment to get accurate coverage
            distances_sq = ((sampled_pixels[:, np.newaxis, :] - centroids) ** 2).sum(
                axis=2
            )
            assignments = np.argmin(distances_sq, axis=1)

            # Calculate coverage for each color
            counts = np.bincount(assignments, minlength=num_colors)
            coverages = counts / len(sampled_pixels)

            # Sort colors by dominance
            sorted_indices = np.argsort(counts)[::-1]

            # Build result dictionary with RGB colors and coverage
            result = {}
            for idx in sorted_indices:
                if counts[idx] > 0:  # Only include colors that appear
                    color_rgb = tuple(int(c) for c in np.clip(centroids[idx], 0, 255))
                    coverage = float(coverages[idx])  # Ensure it's a Python float
                    result[color_rgb] = coverage

            end = time.perf_counter()
            logging.warning(f"Kmeans time: {end - start}")
            return result

    except Exception as e:
        raise RuntimeError(f"Error extracting colors: {str(e)}")


def get_colors(
    image_path: str,
    num_colors: int = 8,
    preset: str = "balanced",
    sort_by: str = "luma",
) -> list[ColorData]:
    """
    Extract dominant colors from an image.
    Args:
        sort_by: Sort colors by 'luma' or 'coverage' (default: 'luma')
    Returns:
        List of ColorData[RGB,coverage,luma]
    """
    SUPPORTED_PRESET = ["high", "balanced", "fast"]
    SUPPORTED_SORT = ["luma", "coverage"]

    if preset not in SUPPORTED_PRESET:
        raise ValueError(
            f"{preset} is not a valid Preset. Select something from {', '.join(SUPPORTED_PRESET)}"
        )

    if sort_by not in SUPPORTED_SORT:
        raise ValueError(
            f"{sort_by} is not a valid sort option. Select something from {', '.join(SUPPORTED_SORT)}"
        )

    resize_dim: tuple[int, int]
    pixel_sample_count: int
    kmeans_iteration: int
    if preset == "fast":
        resize_dim = (100, 100)
        pixel_sample_count = 1000
        kmeans_iteration = 5
    elif preset == "high":
        resize_dim = (500, 500)
        pixel_sample_count = 10000
        kmeans_iteration = 20
    else:  # balanced
        resize_dim = (150, 150)
        pixel_sample_count = 4000
        kmeans_iteration = 10

    extracted_colors: dict = extract_colors_kmeans(
        image_path=image_path,
        num_colors=num_colors,
        resize_dim=resize_dim,
        pixel_sample_count=pixel_sample_count,
        kmeans_iteration=kmeans_iteration,
    )

    extract_start_time = time.perf_counter()
    color_data_list = []
    for rgb, coverage in extracted_colors.items():
        luma_value = round(luma(*rgb), 3)
        color_data_list.append(
            ColorData(
                RGB(*rgb),
                coverage,
                luma_value,
            )
        )

    # Sort by the specified key
    if sort_by == "luma":
        color_data_list.sort(key=lambda x: x.luma, reverse=True)

    else:
        color_data_list.sort(key=lambda x: x.coverage, reverse=True)

    extract_end_time = time.perf_counter()
    logging.info(f"Color Data took {extract_end_time - extract_start_time}")
    return color_data_list
